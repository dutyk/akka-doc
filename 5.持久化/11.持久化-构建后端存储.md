日志和快照存储的存储后端作为Akka持久性扩展的插件。 持久性日志和快照存储插件的目录位于Akka社区项目页面上，请参阅社区插件。本文档介绍了如何构建新的存储后端。
应用程序可以通过实现插件API并通过配置激活它们来提供自己的插件。 插件开发需要以下导入：
```java
import akka.dispatch.Futures;
import akka.persistence.*;
import akka.persistence.journal.japi.*;
import akka.persistence.snapshot.japi.*;
```
# 日志插件API
日志插件扩展了AsyncWriteJournal。
AsyncWriteJournal是一个actor，要实现的方法是：
```xml
/**
 * Java API, Plugin API: asynchronously writes a batch (`Iterable`) of persistent messages to the * journal. * * <p>The batch is only for performance reasons, i.e. all messages don't have to be written * atomically. Higher throughput can typically be achieved by using batch inserts of many records * compared to inserting records one-by-one, but this aspect depends on the underlying data store * and a journal implementation can implement it as efficient as possible. Journals should aim to * persist events in-order for a given `persistenceId` as otherwise in case of a failure, the * persistent state may be end up being inconsistent. * * <p>Each `AtomicWrite` message contains the single `PersistentRepr` that corresponds to the * event that was passed to the `persist` method of the `PersistentActor`, or it contains several * `PersistentRepr` that corresponds to the events that were passed to the `persistAll` method of * the `PersistentActor`. All `PersistentRepr` of the `AtomicWrite` must be written to the data * store atomically, i.e. all or none must be stored. If the journal (data store) cannot support * atomic writes of multiple events it should reject such writes with an `Optional` with an * `UnsupportedOperationException` describing the issue. This limitation should also be documented * by the journal plugin. * * <p>If there are failures when storing any of the messages in the batch the returned `Future` * must be completed with failure. The `Future` must only be completed with success when all * messages in the batch have been confirmed to be stored successfully, i.e. they will be * readable, and visible, in a subsequent replay. If there is uncertainty about if the messages * were stored or not the `Future` must be completed with failure. * * <p>Data store connection problems must be signaled by completing the `Future` with failure. * * <p>The journal can also signal that it rejects individual messages (`AtomicWrite`) by the * returned `Iterable&lt;Optional&lt;Exception&gt;&gt;`. The returned `Iterable` must have as many * elements as the input `messages` `Iterable`. Each `Optional` element signals if the * corresponding `AtomicWrite` is rejected or not, with an exception describing the problem. * Rejecting a message means it was not stored, i.e. it must not be included in a later replay. * Rejecting a message is typically done before attempting to store it, e.g. because of * serialization error. * * <p>Data store connection problems must not be signaled as rejections. * * <p>Note that it is possible to reduce number of allocations by caching some result `Iterable` * for the happy path, i.e. when no messages are rejected. * * <p>Calls to this method are serialized by the enclosing journal actor. If you spawn work in * asynchronous tasks it is alright that they complete the futures in any order, but the actual * writes for a specific persistenceId should be serialized to avoid issues such as events of a * later write are visible to consumers (query side, or replay) before the events of an earlier * write are visible. This can also be done with consistent hashing if it is too fine grained to * do it on the persistenceId level. Normally a `PersistentActor` will only have one outstanding * write request to the journal but it may emit several write requests when `persistAsync` is used * and the max batch size is reached. * * <p>This call is protected with a circuit-breaker. */Future<Iterable<Optional<Exception>>> doAsyncWriteMessages(Iterable<AtomicWrite> messages);
/**
 * Java API, Plugin API: synchronously deletes all persistent messages up to `toSequenceNr`. * * <p>This call is protected with a circuit-breaker. * * @see AsyncRecoveryPlugin */Future<Void> doAsyncDeleteMessagesTo(String persistenceId, long toSequenceNr);
```
如果存储后端API仅支持同步阻塞写入，则这些方法应实现为：
```java
@Override
public Future<Iterable<Optional<Exception>>> doAsyncWriteMessages(
 Iterable<AtomicWrite> messages) { try { Iterable<Optional<Exception>> result = new ArrayList<Optional<Exception>>(); // blocking call here... // result.add(..) return Futures.successful(result); } catch (Exception e) { return Futures.failed(e); }}
```
日志插件还必须实现AsyncRecovery定义的方法：重播和恢复序列号：
```java
/**
 * Java API, Plugin API: asynchronously replays persistent messages. Implementations replay a * message by calling `replayCallback`. The returned future must be completed when all messages * (matching the sequence number bounds) have been replayed. The future must be completed with a * failure if any of the persistent messages could not be replayed. * * <p>The `replayCallback` must also be called with messages that have been marked as deleted. In * this case a replayed message's `deleted` method must return `true`. * * <p>The `toSequenceNr` is the lowest of what was returned by {@link * #doAsyncReadHighestSequenceNr} and what the user specified as recovery {@link * akka.persistence.Recovery} parameter. * * @param persistenceId id of the persistent actor. * @param fromSequenceNr sequence number where replay should start (inclusive). * @param toSequenceNr sequence number where replay should end (inclusive). * @param max maximum number of messages to be replayed. * @param replayCallback called to replay a single message. Can be called from any thread. */Future<Void> doAsyncReplayMessages(
 String persistenceId, long fromSequenceNr, long toSequenceNr, long max, Consumer<PersistentRepr> replayCallback);
/**
 * Java API, Plugin API: asynchronously reads the highest stored sequence number for the given * `persistenceId`. The persistent actor will use the highest sequence number after recovery as * the starting point when persisting new events. This sequence number is also used as * `toSequenceNr` in subsequent call to [[#asyncReplayMessages]] unless the user has specified a * lower `toSequenceNr`. * * @param persistenceId id of the persistent actor. * @param fromSequenceNr hint where to start searching for the highest sequence number. */Future<Long> doAsyncReadHighestSequenceNr(String persistenceId, long fromSequenceNr);
```
可以使用以下最小配置来激活日志插件：
```xml
# Path to the journal plugin to be used
akka.persistence.journal.plugin = "my-journal"
# My custom journal plugin
my-journal {
 # Class name of the plugin. class = "docs.persistence.MyJournal" # Dispatcher for the plugin actor. plugin-dispatcher = "akka.actor.default-dispatcher"}
```
日志插件实例是一个actor，因此与来自持久actor的请求相对应的方法将按顺序执行。它可以委托给异步库，产生futures，或者委托给其他actor以实现并行性。
日志插件类必须具有带有以下签名之一的构造函数：
- 具有一个com.typesafe.config.Config参数和一个用于配置路径的String参数的构造函数
- 具有一个com.typesafe.config.Config参数的构造函数
- 没有参数的构造函数
actor系统配置的插件部分将在config构造函数参数中传递。插件的配置路径在String参数中传递。
plugin-dispatcher是用于插件actor的调度程序。如果未指定，则默认为akka.persistence.dispatchers.default-plugin-dispatcher。
不要在系统默认调度程序上运行日志任务/future，因为这可能会使其他任务饿死。
# 快照存储插件API
快照存储插件必须扩展SnapshotStore actor并实现以下方法：
```java
/**
 * Java API, Plugin API: asynchronously loads a snapshot. * * @param persistenceId id of the persistent actor. * @param criteria selection criteria for loading. */Future<Optional<SelectedSnapshot>> doLoadAsync(
 String persistenceId, SnapshotSelectionCriteria criteria);
/**
 * Java API, Plugin API: asynchronously saves a snapshot. * * @param metadata snapshot metadata. * @param snapshot snapshot. */Future<Void> doSaveAsync(SnapshotMetadata metadata, Object snapshot);
/**
 * Java API, Plugin API: deletes the snapshot identified by `metadata`. * * @param metadata snapshot metadata. */Future<Void> doDeleteAsync(SnapshotMetadata metadata);
/**
 * Java API, Plugin API: deletes all snapshots matching `criteria`. * * @param persistenceId id of the persistent actor. * @param criteria selection criteria for deleting. */Future<Void> doDeleteAsync(String persistenceId, SnapshotSelectionCriteria criteria);
可以使用以下最低配置来激活快照存储插件：
# Path to the snapshot store plugin to be used
akka.persistence.snapshot-store.plugin = "my-snapshot-store"
# My custom snapshot store plugin
my-snapshot-store {
 # Class name of the plugin. class = "docs.persistence.MySnapshotStore" # Dispatcher for the plugin actor. plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"}
```
快照存储实例是一个actor，因此与来自持久actor的请求相对应的方法将按顺序执行。它可以委托给异步库，产生future，或者委托给其他actor以实现并行性。
快照存储插件类必须具有带有以下签名之一的构造函数：
- 具有一个com.typesafe.config.Config参数和一个用于配置路径的String参数的构造函数
- 具有一个com.typesafe.config.Config参数的构造函数
- 没有参数的构造函数
actor系统配置的插件部分将在config构造函数参数中传递。插件的配置路径在String参数中传递。
plugin-dispatcher是用于插件actor的调度程序。如果未指定，则默认为akka.persistence.dispatchers.default-plugin-dispatcher。
不要在系统默认的调度程序上运行快照存储任务/功能，因为那样可能会使其他任务饿死。
# 插件TCK
为了帮助开发人员构建正确且高质量的存储插件，我们提供了技术兼容性套件(简称TCK)。
TCK可用于Java和Scala项目。为了测试您的实现(独立于语言)，您需要包括akka-persistence-tck依赖项：
```xml
<properties>
 <akka.version>2.6.8</akka.version> <scala.binary.version>2.13</scala.binary.version></properties>
<dependency>
 <groupId>com.typesafe.akka</groupId> <artifactId>akka-persistence-tck_${scala.binary.version}</artifactId> <version>${akka.version}</version></dependency>
```
要将Journal TCK测试包括在您的测试套件中，只需扩展提供的JavaJournalSpec：
```java
@RunWith(JUnitRunner.class)
class MyJournalSpecTest extends JavaJournalSpec {
 public MyJournalSpecTest() { super( ConfigFactory.parseString( "persistence.journal.plugin = " + ""akka.persistence.journal.leveldb-shared"")); }
 @Override public CapabilityFlag supportsRejectingNonSerializableObjects() { return CapabilityFlag.off(); }}
```
请注意，某些测试是可选的，并且通过覆盖supports...方法，可以为TCK提供有关要运行哪些测试的所需信息。 您可以使用提供的CapabilityFlag.on/CapabilityFlag.off值来实现这些方法。
我们还提供了一个简单的基准测试类JavaJournalPerfSpec，其中包括JavaJournalSpec进行的所有测试，并且在打印其性能统计信息时还对Journal进行了更长的操作。 虽然它并非旨在提供适当的基准测试环境，但可以用来粗略了解日志在大多数典型情况下的表现。
为了在您的测试套件中包括SnapshotStore TCK测试，请扩展SnapshotStoreSpec：
```java
@RunWith(JUnitRunner.class)
class MySnapshotStoreTest extends JavaSnapshotStoreSpec {
 public MySnapshotStoreTest() { super( ConfigFactory.parseString( "akka.persistence.snapshot-store.plugin = " + ""akka.persistence.snapshot-store.local"")); }}
```
如果您的插件需要一些设置(启动模拟数据库，删除临时文件等)，则可以覆盖beforeAll和afterAll方法以挂入测试生命周期：
```java
@RunWith(JUnitRunner.class)
class MyJournalSpecTest extends JavaJournalSpec {
 List<File> storageLocations = new ArrayList<File>();
 public MyJournalSpecTest() { super( ConfigFactory.parseString( "persistence.journal.plugin = " + ""akka.persistence.journal.leveldb-shared""));
 Config config = system().settings().config(); storageLocations.add( new File(config.getString("akka.persistence.journal.leveldb.dir"))); storageLocations.add( new File(config.getString("akka.persistence.snapshot-store.local.dir"))); }
 @Override public CapabilityFlag supportsRejectingNonSerializableObjects() { return CapabilityFlag.on(); }
 @Override public void beforeAll() { for (File storageLocation : storageLocations) { FileUtils.deleteRecursively(storageLocation); } super.beforeAll(); }
 @Override public void afterAll() { super.afterAll(); for (File storageLocation : storageLocations) { FileUtils.deleteRecursively(storageLocation); } }}
```
我们强烈建议您在测试套件中包括这些规范，因为它们涵盖了从头编写插件时可能会忘记测试的多种情况。
# 损坏的事件日志
如果日志无法阻止用户同时运行具有相同persistenceId的持久actor，则事件日志可能会因具有相同序列号的事件而被破坏。
建议日志在恢复过程中仍应传递这些事件，以便可以使用replay-filter以与日志无关的方式来决定如何处理。