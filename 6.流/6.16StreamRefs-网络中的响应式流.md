# 依赖
要使用Akka Streams，请将模块添加到您的项目中：
```xml
<properties>
 <akka.version>2.6.10</akka.version> <scala.binary.version>2.13</scala.binary.version></properties>
<dependency>
 <groupId>com.typesafe.akka</groupId> <artifactId>akka-stream_${scala.binary.version}</artifactId> <version>${akka.version}</version></dependency>
```
# 介绍
>警告
该模块当前被标记为在最终开发的主题上可能发生变化。这意味着API或语义可以在没有警告或弃用期限的情况下进行更改，因此不建议在生产中使用此模块。
流引用(简称“流引用”)允许在Akka集群中的多个节点上运行Akka流。
与较重的“流数据处理”框架不同，Akka流既不“部署”也不自动分发。顾名思义，Akka流引用是对流的现有部分的引用，可用于创建分布式处理框架或在应用程序的特定部分引入此类功能。
在现有的集群Akka应用程序中使用流引用很简单，不需要其他配置或设置。它们自动维护网络上的流量控制/背压，并采用Akka的故障检测机制来在远程节点发生故障时快速进行故障排除(“让它崩溃！”)。它们可以看作是“工作拉动模式”的一种实现，否则将需要手动实现。
>注意
思考流引用的一种有用方法是：“就像ActorRef，但适用于Akka流的Source和Sink”。
流引用是指已经存在的，可能是远程的接收器或源。不要将远程部署流误认为是该功能不适合的。
>重要
在Akka Cluster中使用流引用。如果使用普通的Akka远程处理，则故障检测器可能会导致隔离。
## 流参考
流引用的主要用例是在期望两个实体之间长期运行数据流的系统中替换原始actor或HTTP消息传递。通常，它们可以用于有效地实现点对点流传输，而无需设置其他消息代理或类似的辅助集群。
流引用非常适合您需要以流控制方式在节点之间发送消息的任何系统。典型示例包括：向工作节点尽快发送工作请求，但发送速度不超过工作节点可以处理的请求，或者向下游发送处理速度可能较慢的数据元素。建议在基于actor消息的系统中混合并引入流引用，在该系统中，actor消息用于编排和准备此类消息流，随后使用流引用来进行流控制的消息传输。
流引用不是持久的。但是，通过在actor消息传递层中引入这样的协议来构建可恢复流很简单。绝对希望流引用通过Akka集群通过Akka远程发送到集群中的其他节点，因此，与普通的Actor消息互补而不是竞争。通常会使用Actor通过一些初始消息来建立流，即“我想为您提供许多日志元素(流引用)”，或者相反，“如果您需要向我发送很多数据，这是流引用，可以这样做”。
由于每个引用的两侧(“本地”和“远程”)可能会混淆地称为“远程”和“本地”，因为根据我们的观察方式，任何一方都可以视为“本地”或“远程”它–我们建议使用术语“起源”和“目标”，这由创建流引用的位置定义。对于SourceRefs，“原点”是具有要流出的数据的那一侧。对于SinkRefs，“来源”侧是准备接收数据并已分配引用的actor系统。这两个可能被视为彼此的对偶。但是，为了解释有关共享引用的模式，我们发现此措辞非常有用。
## 源引用-向远程系统提供流数据
可以将“SourceRef”提供给远程actor系统，以便使用我们在本地准备的某些数据源。
为了与远程端点共享Source，您需要通过将其运行到Sink.sourceRef中来实现它。该接收器实现了SourceRef，然后可以将其发送到其他节点。
```java
static class RequestLogs {
 public final long streamId;
 public RequestLogs(long streamId) { this.streamId = streamId; }}
static class LogsOffer {
 final SourceRef<String> sourceRef;
 public LogsOffer(SourceRef<String> sourceRef) { this.sourceRef = sourceRef; }}
static class DataSource extends AbstractActor {
 @Override public Receive createReceive() { return receiveBuilder().match(RequestLogs.class, this::handleRequestLogs).build(); }
 private void handleRequestLogs(RequestLogs requestLogs) { Source<String, NotUsed> logs = streamLogs(requestLogs.streamId); SourceRef<String> logsRef = logs.runWith(StreamRefs.sourceRef(), mat);
 getSender().tell(new LogsOffer(logsRef), getSelf()); }
 private Source<String, NotUsed> streamLogs(long streamId) { return Source.repeat("[INFO] some interesting logs here (for id: " + streamId + ")"); }}
``` 在创建Source时，创建并拥有Source的Origin actor也可以执行一些验证或其他设置。一旦分发了SourceRef，远程端就可以像这样运行它：
```java
ActorRef sourceActor = system.actorOf(Props.create(DataSource.class), "dataSource");
sourceActor.tell(new RequestLogs(1337), getTestActor());
LogsOffer offer = expectMsgClass(LogsOffer.class);
offer.sourceRef.getSource().runWith(Sink.foreach(log -> System.out.println(log)), mat);
```
下面的动画显示了准备和运行由SourceRef驱动的分布式流的过程：
![avatar](https://doc.akka.io/docs/akka/current/images/source-ref-animation.gif)
>警告
SourceRef设计为“单次”；即，它只能实现一次。这是为了不使实现的心理模型复杂化。
可以通过以下方式模拟多播：启动一次BroadcastHub运算符，然后向其附加多个新流，每个流都发出一个新的流引用。这样，BroadcastHubs Source的实现会创建一个唯一的单发流ref，但是它们都可以使用单个Source(位于BroadcastHub运算符之前)。
## Sink Refs-提供从远程系统接收流数据的功能
SourceRef的对偶。
它们可用于为另一端提供以流流控制方式将数据发送到源端的功能。此处的来源分配了一个Sink，它可以像Sink.foreach一样简单，也可以像复杂的Sink一样高级，后者将传入的数据流传输到其他各种系统(例如，Alpakka提供的任何Sink)。
>注意
为了形成一个好的SinkRefs思维模型，您可以认为它们类似于FTP中的“被动模式”。
```java
static class PrepareUpload {
 final String id;
 public PrepareUpload(String id) { this.id = id; }}
static class MeasurementsSinkReady {
 final String id; final SinkRef<String> sinkRef;
 public MeasurementsSinkReady(String id, SinkRef<String> ref) { this.id = id; this.sinkRef = ref; }}
static class DataReceiver extends AbstractActor {
 @Override public Receive createReceive() { return receiveBuilder() .match( PrepareUpload.class, prepare -> { Sink<String, NotUsed> sink = logsSinkFor(prepare.id); SinkRef<String> sinkRef = StreamRefs.<String>sinkRef().to(sink).run(mat);
 getSender().tell(new MeasurementsSinkReady(prepare.id, sinkRef), getSelf()); }) .build(); }
 private Sink<String, NotUsed> logsSinkFor(String id) { return Sink.<String>ignore().mapMaterializedValue(done -> NotUsed.getInstance()); }}
```
使用提供的SinkRef将数据发送到Sink的源也很简单，因为我们可以将SinkRef视为其他任何Sink并直接运行或运行它。
```java
ActorRef receiver = system.actorOf(Props.create(DataReceiver.class), "dataReceiver");
receiver.tell(new PrepareUpload("system-42-tmp"), getTestActor());
MeasurementsSinkReady ready = expectMsgClass(MeasurementsSinkReady.class);
Source.repeat("hello").runWith(ready.sinkRef.getSink(), mat);
```
下面的动画显示了准备和运行由SinkRef驱动的分布式流的过程：
![avatar](https://doc.akka.io/docs/akka/current/images/sink-ref-animation.gif)
>警告
SinkRef是设计使然的“单发”。即，它只能实现一次。这是为了不使实现的心理模型复杂化。
如果您有使用案例来构建一个扇入操作，该操作接受来自多个远程节点的写入，则可以构建您的Sink并在其前面添加一个MergeHub运算符，每次实现针对该MergeHub的新SinkRef。这具有使您完全控制如何合并这些流的附加好处(即，通过使用“合并首选”或扇入运算符的任何其他变体)。
## 传递保证
流引用将正常的actor消息传递用于他们的传输，因此提供了相同水平的基本交付保证。流引用确实通过需求重新传递和顺序故障检测在某种程度上扩展了语义。换一种说法：
- 消息是通过actor远程发送的
 - 依靠TCP(经典远程处理或Artery TCP)或Aeron UDP进行基本的重新交付机制
- 消息保证是有序的
- 消息可能会丢失，但是：
 - 需求下降的信号将自动重新发送(类似于系统消息)
 - 丢失的元素信号将导致流失败
# 批量流引用
>警告
批量流引用尚未实现。请参阅故障单批量传输流参考号＃24276来跟踪此功能的进度或信号需求。
批量流引用可用于创建简单的旁通道，以传输大量数据，例如巨大的日志文件，消息或媒体，就像本地琐碎流一样容易。
# SourceRef和SinkRef的序列化
StreamRefs需要序列化，因为重点是在集群的节点之间发送它们。直接将SourceRef和SinkRef作为消息发送时，会提供一个内置的序列化程序，但是建议的用法是将它们包装到您自己的actor消息类中。
使用Akka Jackson时，包装后的SourceRef和SinkRef的序列化将立即可用。
如果您使用其他某种形式的序列化，则需要使用序列化程序中的StreamRefResolver扩展来获取SourceRef和SinkRef。该扩展提供了toSerializationFormat(接收器或源)的方法，以将引用从引用转换为字符串，并解析{Sink，Source} Ref(字符串)以解析来自字符串的引用。
# 组态
## 流参考订阅超时
所有流引用都具有订阅超时，这旨在防止资源泄漏，以防远程节点请求分配许多流但从不实际运行它们。为了防止这种情况，每个流引用都有默认超时(30秒)，如果目标尚未实现流引用，则源将中止流提供。触发超时后，目标端的实现将失败，指出起点已丢失。
由于根据提供的流的类型，这些超时通常会非常不同，并且在同一应用程序中可能存在许多不同的超时，因此不仅可以全局配置此设置(akka.stream.materializer.stream-ref。订阅超时)，也可以通过属性：
```java
FiniteDuration timeout = FiniteDuration.create(5, TimeUnit.SECONDS);
Attributes timeoutAttributes = StreamRefAttributes.subscriptionTimeout(timeout);
// configuring Sink.sourceRef (notice that we apply the attributes to the Sink!):
Source.repeat("hello")
 .runWith(StreamRefs.<String>sourceRef().addAttributes(timeoutAttributes), mat);
// configuring SinkRef.source:
StreamRefs.<String>sinkRef()
 .addAttributes(timeoutAttributes) .runWith(Sink.<String>ignore(), mat); // not very interesting sink, just an example```
# 常规配置
通过覆盖akka.stream.materializer.stream-ref.*键空间中的以下任何值，可以在application.conf中全局设置其他设置：
```conf
# configure defaults for SourceRef and SinkRef
stream-ref {
 # Buffer of a SinkRef that is used to batch Request elements from the other side of the stream ref # # The buffer will be attempted to be filled eagerly even while the local stage did not request elements, # because the delay of requesting over network boundaries is much higher. buffer-capacity = 32
 # Demand is signalled by sending a cumulative demand message ("requesting messages until the n-th sequence number) # Using a cumulative demand model allows us to re-deliver the demand message in case of message loss (which should # be very rare in any case, yet possible -- mostly under connection break-down and re-establishment). # # The semantics of handling and updating the demand however are in-line with what Reactive Streams dictates. # # In normal operation, demand is signalled in response to arriving elements, however if no new elements arrive # within `demand-redelivery-interval` a re-delivery of the demand will be triggered, assuming that it may have gotten lost. demand-redelivery-interval = 1 second
 # Subscription timeout, during which the "remote side" MUST subscribe (materialize) the handed out stream ref. # This timeout does not have to be very low in normal situations, since the remote side may also need to # prepare things before it is ready to materialize the reference. However the timeout is needed to avoid leaking # in-active streams which are never subscribed to. subscription-timeout = 30 seconds
 # In order to guard the receiving end of a stream ref from never terminating (since awaiting a Completion or Failed # message) after / before a Terminated is seen, a special timeout is applied once Terminated is received by it. # This allows us to terminate stream refs that have been targeted to other nodes which are Downed, and as such the # other side of the stream ref would never send the "final" terminal message. # # The timeout specifically means the time between the Terminated signal being received and when the local SourceRef # determines to fail itself, assuming there was message loss or a complete partition of the completion signal. final-termination-signal-deadline = 2 seconds}
```