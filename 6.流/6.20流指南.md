# 依赖
要使用Akka Streams，请将模块添加到您的项目中：
```xml
<properties>
 <akka.version>2.6.10</akka.version> 
 <scala.binary.version>2.13</scala.binary.version>
</properties>
<dependency>
 <groupId>com.typesafe.akka</groupId> 
 <artifactId>akka-stream_${scala.binary.version}</artifactId> 
 <version>${akka.version}</version>
</dependency>
```
# 介绍
这是一组模式，通过解决“食谱”格式的小目标问题，展示了Akka Streams API的各种用法。该页面的目的是为如何处理涉及流的各种小任务提供灵感和想法。此页面中的食谱可以直接使用，但是作为起点，它们是最强大的：强烈建议自定义代码段。
这部分还作为文档主体的补充材料。在阅读手册的同时打开此页面是一个好主意，并查找示例，这些示例演示了文档主体中出现的各种流概念。
如果需要快速参考配方中可用的运算符，请参阅运算符索引。
# 处理流程
在这个系列中，我们展示了涉及线性流的简单配方。本节中的配方相当笼统，有针对性的配方可作为单独的部分使用(缓冲区和使用速率，使用流IO)。
## 流日志记录
情况：在开发过程中，查看流的特定部分中发生的情况有时会很有帮助。
最简单的解决方案是使用映射操作，并使用println将接收到的元素打印到控制台。尽管此配方非常简单，但通常适合于快速调试会话。
```java
mySource.map(
 elem -> { System.out.println(elem); return elem; });```
记录日志的另一种方法是使用log()操作。 这种方法为流经流的元素，流的完成和失败提供了更细粒度的日志记录级别控制。
```java
// customise log levels
mySource
 .log("before-map") .withAttributes( Attributes.createLogLevels( Logging.WarningLevel(), // onElement Logging.InfoLevel(), // onFinish Logging.DebugLevel() // onFailure )) .map(i -> analyse(i));
// or provide custom logging adapter
final LoggingAdapter adapter = Logging.getLogger(system, "customLogger");
mySource.log("custom", adapter);
```
## 创建持续评估函数的源
情况：只要有需求，就需要一个源来连续提供通过评估给定功能获得的元素。
最简单的实现是使用产生一些任意元素的Source.repeat-例如 NotUsed-然后将这些元素映射到函数求值。 例如,如果我们有一些builderFunction()，我们可以使用：
```java
final Source<String, NotUsed> source =
 Source.repeat(NotUsed.getInstance()).map(elem -> builderFunction());```
注意：如果element-builder函数达到可变状态，则应使用有保证的单线程源； 例如 Source.unfold或Source.unfoldResource。
## 展平序列流
情况：一个流作为元素序列的流给出，但是需要一个元素流，分别将序列中的所有嵌套元素流化。
mapConcat操作可用于使用In-> List <Out>形式的映射器函数来实现元素的一对多转换。 在这种情况下，我们希望将元素列表映射到集合本身中的元素，因此可以调用mapConcat(l-> l)。
```java
Source<List<Message>, NotUsed> myData = someDataSource;
Source<Message, NotUsed> flattened = myData.mapConcat(i -> i);
```
## 将流排放到严格的集合中
情况：一个可能无限的元素序列作为流给出，需要在确保有界性的同时将其收集到Scala集合中
使用流时的一种常见情况是我们需要将传入元素收集到Scala集合中。 通过Sink.seq支持此操作，该实例化为CompletionStage <List <T >>。
为了确保流有界，应始终结合使用函数limit或take，以防止程序耗尽内存。
例如，最好避免这种情况：
```java
// Dangerous: might produce a collection with 2 billion elements!
final CompletionStage<List<String>> strings = mySource.runWith(Sink.seq(), system);
```
而是使用limit或take来确保结果列表仅包含最多MAX_ALLOWED_SIZE个元素：
```java
final int MAX_ALLOWED_SIZE = 100;
// OK. Future will fail with a `StreamLimitReachedException`
// if the number of incoming elements is larger than max
final CompletionStage<List<String>> strings =
 mySource.limit(MAX_ALLOWED_SIZE).runWith(Sink.seq(), system);
// OK. Collect up until max-th elements only, then cancel upstream
final CompletionStage<List<String>> strings =
 mySource.take(MAX_ALLOWED_SIZE).runWith(Sink.seq(), system);```
## 计算ByteString流的摘要
情况：字节流作为ByteString的流给出，我们要计算该流的密码摘要。
该配方使用GraphStage定义自定义的Akka Stream运算符，以托管可变的MessageDigest类(Java密码学API的一部分)，并使用来自流的字节更新它。当流开始时，将调用运算符的onPull处理函数，这会将pull事件冒泡到其上游。作为对此请求的响应，一个ByteString块将到达(onPush)，我们将使用它来更新摘要，然后它将为下一个块进行提取。
最终ByteString的流耗尽，我们通过onUpstreamFinish收到有关此事件的通知。在这一点上，我们想发出摘要值，但是由于可能没有下游需求，因此我们不能直接通过推入此处理程序来实现。取而代之的是，我们调用generate来临时替换处理程序，在需求出现时发出提供的值，然后重置算子状态。然后它将完成算子。
```java
class DigestCalculator extends GraphStage<FlowShape<ByteString, ByteString>> {
 private final String algorithm; public Inlet<ByteString> in = Inlet.create("DigestCalculator.in"); public Outlet<ByteString> out = Outlet.create("DigestCalculator.out"); private FlowShape<ByteString, ByteString> shape = FlowShape.of(in, out);
 public DigestCalculator(String algorithm) { this.algorithm = algorithm; }
 @Override public FlowShape<ByteString, ByteString> shape() { return shape; }
 @Override public GraphStageLogic createLogic(Attributes inheritedAttributes) { return new GraphStageLogic(shape) { final MessageDigest digest;
 { try { digest = MessageDigest.getInstance(algorithm); } catch (NoSuchAlgorithmException ex) { throw new RuntimeException(ex); }
 setHandler( out, new AbstractOutHandler() { @Override public void onPull() { pull(in); } });
 setHandler( in, new AbstractInHandler() { @Override public void onPush() { ByteString chunk = grab(in); digest.update(chunk.toArray()); pull(in); }
 @Override public void onUpstreamFinish() { // If the stream is finished, we need to emit the digest // before completing emit(out, ByteString.fromArray(digest.digest())); completeStage(); } }); } }; }}
```
## 从ByteStrings流中解析行
情况：字节流是作为ByteString的流给出的，其中包含需要解析的以行结束符终止的行(或者，包含以特殊定界符字节序列定界的二进制帧)。
Framing helper类包含一个方便的方法来解析ByteString流中的消息：
```java
final Source<String, NotUsed> lines =
 rawData .via(Framing.delimiter(ByteString.fromString("rn"), 100, FramingTruncation.ALLOW)) .map(b -> b.utf8String());```
## 处理压缩数据流
情况：压缩后的字节流作为ByteString的流给出，例如从FileIO源。
Compression helper类包含用于解压缩使用Gzip或Deflate压缩的数据流的便捷方法。
```java
final Source<ByteString, NotUsed> decompressedStream =
 compressedStream.via(Compression.gunzip(100));```
## 实施按密钥还原
情况：给定元素流，我们想在元素的不同子组上计算一些合计值。
按键减少样式操作的“hello world”是字数统计，我们在下面演示。给定单词流，我们首先创建一个新的流，根据i-> i函数对单词进行分组，即现在我们有了一个流，其中每个子流将为相同的单词提供服务。
为了计算单词，我们需要处理流(包含相同单词的实际组)。 groupBy返回一个SubSource，这意味着我们直接转换结果子流。在这种情况下，我们使用reduce运算符将单词本身及其在Pair<String，Integer>中的出现次数进行聚合。当整个输入完成时，每个子流将发出一个最终值(准确地说就是这样一个对)。最后一步，我们将这些值从子流中合并回单个输出流中。
一个值得注意的细节与MAXIMUM_DISTINCT_WORDS参数有关：这定义了groupBy和merge操作的宽度。 Akka Streams专注于有限的资源消耗，并且合并运算符的并发打开输入的数量描述了合并本身所需的资源量。因此，在任何给定时间只能激活有限数量的子流。如果groupBy运算符遇到的密钥多于此数字，则该流将无法继续而不违反其资源限制，在这种情况下，groupBy将以失败而终止。
```java
final int MAXIMUM_DISTINCT_WORDS = 1000;
final Source<Pair<String, Integer>, NotUsed> counts =
 words // split the words into separate streams first .groupBy(MAXIMUM_DISTINCT_WORDS, i -> i) // transform each element to pair with number of words in it .map(i -> new Pair<>(i, 1)) // add counting logic to the streams .reduce((left, right) -> new Pair<>(left.first(), left.second() + right.second())) // get a stream of word counts .mergeSubstreams();```
通过将单词计数特定的部分提取到
- 定义组的groupKey函数
- 映射将每个元素映射到子流上的reduce使用的值
- 进行实际reduce的reduce函数
我们在下面得到一个广义的版本：
```java
public static <In, K, Out> Flow<In, Pair<K, Out>, NotUsed> reduceByKey(
 int maximumGroupSize, Function<In, K> groupKey, Function<In, Out> map, Function2<Out, Out, Out> reduce) {
 return Flow.<In>create() .groupBy(maximumGroupSize, groupKey) .map(i -> new Pair<>(groupKey.apply(i), map.apply(i))) .reduce( (left, right) -> new Pair<>(left.first(), reduce.apply(left.second(), right.second()))) .mergeSubstreams();}
```
>注意
请注意，我们上面讨论的reduce-by-key版本在读取整个输入流时是顺序的，换句话说，它不是像MapReduce和类似框架这样的并行化模式。
## 使用groupBy将元素排序到多个组
情况：groupBy操作严格划分传入元素，每个元素恰好属于一个组。 有时我们想同时将元素映射到多个组中。
为了达到预期的结果，我们分两个步骤解决问题：
首先，使用给定消息所属主题(组)列表的topicMapper函数，将消息流转换为Pair <Message，Topic>流，其中对于每个主题，将发出属于单独对的消息对 。 这是通过使用mapConcat实现的
然后，我们使用这个新的消息主题对流(对于给定消息所属的每个主题都包含一个单独的对)，并使用主题作为组键将其馈入groupBy。
```java
final Function<Message, List<Topic>> topicMapper = m -> extractTopics(m);
final Source<Pair<Message, Topic>, NotUsed> messageAndTopic =
 elems.mapConcat( (Message msg) -> { List<Topic> topicsForMessage = topicMapper.apply(msg); // Create a (Msg, Topic) pair for each of the topics
 // the message belongs to return topicsForMessage.stream() .map(topic -> new Pair<Message, Topic>(msg, topic)) .collect(toList()); });
SubSource<Pair<Message, Topic>, NotUsed> multiGroups =
 messageAndTopic .groupBy(2, pair -> pair.second()) .map( pair -> { Message message = pair.first(); Topic topic = pair.second();
 // do what needs to be done });```
## 临时来源
情况：想法是您有一个来源，直到有需求才开始。 另外，您希望在没有更多需求时将其关闭，然后再次启动时又有新需求。
您可以通过如下组合延迟，backpressureTimeout和recoverWithRetries来实现此行为：
```java
public <T> Source<T, ?> adhocSource(Source<T, ?> source, Duration timeout, int maxRetries) {
 return Source.lazily( () -> source .backpressureTimeout(timeout) .recoverWithRetries( maxRetries, new PFBuilder() .match( TimeoutException.class, ex -> Source.lazily(() -> source.backpressureTimeout(timeout))) .build()));}
```
# 与算子合作
在这个集合中，我们展示了使用流运算符实现各种目标的配方。
## 以编程方式触发元素流
情况：给定元素流，我们希望根据触发信号控制这些元素的发射。 换句话说，即使流将能够流动(不被反压)，我们也要保留元素，直到触发信号到达为止。
此配方通过将Message元素流与Trigger信号流压缩在一起解决了该问题。 由于Zip生成对，因此我们选择了该对的第一个元素来映射输出流。
```java
final RunnableGraph<Pair<TestPublisher.Probe<Trigger>, TestSubscriber.Probe<Message>>> g =
 RunnableGraph .<Pair<TestPublisher.Probe<Trigger>, TestSubscriber.Probe<Message>>>fromGraph( GraphDSL.create( triggerSource, messageSink, (p, s) -> new Pair<>(p, s), (builder, source, sink) -> { SourceShape<Message> elements = builder.add( Source.from(Arrays.asList("1", "2", "3", "4")) .map(t -> new Message(t))); FlowShape<Pair<Message, Trigger>, Message> takeMessage = builder.add( Flow.<Pair<Message, Trigger>>create().map(p -> p.first())); final FanInShape2<Message, Trigger, Pair<Message, Trigger>> zip = builder.add(Zip.create()); builder.from(elements).toInlet(zip.in0()); builder.from(source).toInlet(zip.in1()); builder.from(zip.out()).via(takeMessage).to(sink); return ClosedShape.getInstance(); }));```
另外，也可以不使用Zip，然后使用map来获取对中的第一个元素，而可以避免使用ZipWith首先创建对，而ZipWith使用两个参数函数来生成输出元素。 如果此函数返回两个参数对，那将恰好是Zip的行为，因此ZipWith是zipping的概括。
```java
final RunnableGraph<Pair<TestPublisher.Probe<Trigger>, TestSubscriber.Probe<Message>>> g =
 RunnableGraph .<Pair<TestPublisher.Probe<Trigger>, TestSubscriber.Probe<Message>>>fromGraph( GraphDSL.create( triggerSource, messageSink, (p, s) -> new Pair<>(p, s), (builder, source, sink) -> { final SourceShape<Message> elements = builder.add( Source.from(Arrays.asList("1", "2", "3", "4")) .map(t -> new Message(t))); final FanInShape2<Message, Trigger, Message> zipWith = builder.add(ZipWith.create((msg, trigger) -> msg)); builder.from(elements).toInlet(zipWith.in0()); builder.from(source).toInlet(zipWith.in1()); builder.from(zipWith.out()).to(sink); return ClosedShape.getInstance(); }));```
## 使工作与固定的worker平衡
情况：给定一个工作流和一个表示为“流程”的工作程序流程，将创建一个工作程序池，该程序池自动将传入的工作平衡到可用工作程序，然后合并结果。
我们将解决方案表示为一个函数，该函数需要一个工作流程和要分配的worker数量，并提供一个内部包含这些工作人员池的流程。 为了获得期望的结果，我们将创建一个来自算子的流程。
该运算符包含一个“平衡”节点，该节点是一种特殊的扇出操作，试图将元素路由到可用的下游使用者。 在for循环中，我们将所有所需的工作程序连接为该平衡器元素的输出，然后将这些工作程序的输出连接至Merge元素，该元素将从工作程序收集结果。
为了使工人算子并行运行，我们将其标记为异步与异步。
```java
public static <In, Out> Flow<In, Out, NotUsed> balancer(
 Flow<In, Out, NotUsed> worker, int workerCount) { return Flow.fromGraph( GraphDSL.create( b -> { boolean waitForAllDownstreams = true; final UniformFanOutShape<In, In> balance = b.add(Balance.<In>create(workerCount, waitForAllDownstreams)); final UniformFanInShape<Out, Out> merge = b.add(Merge.<Out>create(workerCount));
 for (int i = 0; i < workerCount; i++) { b.from(balance.out(i)).via(b.add(worker.async())).toInlet(merge.in(i)); }
 return FlowShape.of(balance.in(), merge.out()); }));}
```
# 使用速率
该食谱集展示了多种模式，其中上游和下游之间的速率差异需要通过简单的背压以外的其他策略来处理。
## 删除元素
情况：给定一个快速的生产者和缓慢的消费者，我们希望在必要时删除一些元素，以免使生产者的速度减慢太多。
这可以通过使用通用的速率转换操作来解决。 可以将Conflate视为一种特殊的reduce操作，如果需要，可以将多个上游元素折叠为一个聚合元素，以保持上游速度不受下游影响。
当上游速度更快时，合并的还原过程开始。 我们的减速器功能采用了最新鲜的元素。 这是一个简单的删除操作。
```java
final Flow<Message, Message, NotUsed> droppyStream =
 Flow.of(Message.class).conflate((lastMessage, newMessage) -> newMessage);```
有一个更通用的conflate版本，名为conflateWithSeed，它允许表达更复杂的聚合，更类似于折叠。
## 放弃广播
情况：默认的广播运算符已适当地承受了压力，但这意味着速度较慢的下游使用者可以阻止其他下游使用者，从而导致吞吐量降低。 换句话说，广播速率是其最慢的下游用户的速率。 在某些情况下，如果需要，可以通过丢弃元素来允许更快的消费者独立于其较慢的兄弟姐妹前进。
解决此问题的一种方法是在所有下游使用者之前添加一个缓冲元素，以定义丢弃策略，而不是默认的反压。 这允许不同使用者之间的暂时性较小的速率差异(缓冲区消除了较小的速率差异)，但是如果需要，还可以通过从慢速使用者的缓冲区中删除来使较快的使用者继续前进。
```java
// Makes a sink drop elements if too slow
public <T> Sink<T, CompletionStage<Done>> droppySink(
 Sink<T, CompletionStage<Done>> sink, int size) { return Flow.<T>create().buffer(size, OverflowStrategy.dropHead()).toMat(sink, Keep.right());}
```
## 收集错过的ticks
情况：给定常规(滴答)滴答声来源，而不是试图对滴答声产生者施加反压力，我们希望保留未滴答滴答声的计数器，并在可能的情况下传递下去。
我们将使用conflateWithSeed解决问题。合并的种子版本具有两个功能：
- 一个种子函数，当上游比下游快时，该函数会为折叠过程生成零元素。在我们的例子中，种子函数是一个常量函数，由于在该点没有漏掉的滴答声，它返回0。
- 当由于下游处理速率不足而需要将多个上游消息折叠成一个聚合值时调用的折叠函数。我们的折叠功能可增加到目前为止已保存的滴答滴答声的当前计数。
结果，我们有了一个Int流程，其中数字表示错过的滴答声。数字0表示我们能够足够快地消耗滴答声(即零表示：1个不丢失的滴答声+ 0个错过的滴答声)
```java
final Flow<Tick, Integer, NotUsed> missedTicks =
 Flow.of(Tick.class).conflateWithSeed(tick -> 0, (missed, tick) -> missed + 1);```
## 创建一个重复出现的最后一个元素的流处理器
情况：给定一个生产者和一个消费者，两者的比率都事先未知，我们希望通过在必要时从上游丢弃较早的未消耗元素并为下游重复最后一个值来确保它们都不放慢彼此的速度 如有必要。
我们有两种选择来实现此功能。 在这两种情况下，我们都将使用GraphStage来构建我们的自定义运算符。 在第一个版本中，我们将使用提供的初始值initial，如果尚未准备好上游元素，则将用于向下游供料。 在onPush()处理程序中，我们覆盖currentValue变量，并立即通过调用pull()减轻上游压力。 下游的onPull处理程序非常相似，我们通过发出currentValue立即减轻下游的负担。
```java
class HoldWithInitial<T> extends GraphStage<FlowShape<T, T>> {
 public Inlet<T> in = Inlet.<T>create("HoldWithInitial.in"); public Outlet<T> out = Outlet.<T>create("HoldWithInitial.out"); private FlowShape<T, T> shape = FlowShape.of(in, out);
 private final T initial;
 public HoldWithInitial(T initial) { this.initial = initial; }
 @Override public FlowShape<T, T> shape() { return shape; }
 @Override public GraphStageLogic createLogic(Attributes inheritedAttributes) { return new GraphStageLogic(shape) { private T currentValue = initial;
 { setHandler( in, new AbstractInHandler() { @Override public void onPush() throws Exception { currentValue = grab(in); pull(in); } }); setHandler( out, new AbstractOutHandler() { @Override public void onPull() throws Exception { push(out, currentValue); } }); }
 @Override public void preStart() { pull(in); } }; }}
```
尽管相对简单，但是第一个版本的缺点是它需要一个不一定总是可以提供的任意初始元素。 因此，我们创建了第二个版本，其中下游可能需要在一种情况下等待：如果第一个元素尚不可用。
我们引入了一个布尔变量waitingFirstValue来表示是否提供了第一个元素(或者，一个Optional可以用于currentValue，或者如果元素类型是Object的子类，则可以出于相同的目的使用null)。 在下游的onPull()处理程序中，与先前版本的不同之处在于我们检查是否已接收到第一个值，并且仅在拥有时才发出。 这导致当第一个元素进入时，我们必须检查下游是否可能已经有需求，以便在这种情况下我们可以直接推送该元素。
```java
class HoldWithWait<T> extends GraphStage<FlowShape<T, T>> {
 public Inlet<T> in = Inlet.<T>create("HoldWithInitial.in"); public Outlet<T> out = Outlet.<T>create("HoldWithInitial.out"); private FlowShape<T, T> shape = FlowShape.of(in, out);
 @Override public FlowShape<T, T> shape() { return shape; }
 @Override public GraphStageLogic createLogic(Attributes inheritedAttributes) { return new GraphStageLogic(shape) { private T currentValue = null; private boolean waitingFirstValue = true;
 { setHandler( in, new AbstractInHandler() { @Override public void onPush() throws Exception { currentValue = grab(in); if (waitingFirstValue) { waitingFirstValue = false; if (isAvailable(out)) push(out, currentValue); } pull(in); } }); setHandler( out, new AbstractOutHandler() { @Override public void onPull() throws Exception { if (!waitingFirstValue) push(out, currentValue); } }); }
 @Override public void preStart() { pull(in); } }; }}
```
## 全局限制一组流的速率
情况：给定一组无法合并的独立流，我们希望全局限制该组流的总吞吐量。
一种可能的解决方案是使用共享actor作为全局限制器，并与mapAsync结合使用，以创建可重用的Flow，可以将其插入流中以限制其速率。
第一步，我们定义一个actor，该actor将对全局流速限制进行核算。actor维护一个计时器，一个用于等待许可令牌的计数器以及一个可能正在等待actor的队列。actor具有打开和关闭状态。actor仍处于待批准状态时处于打开状态。每当许可请求作为对actor的WantToPass消息到达时，可用许可的数量都会减少，并且我们会通过发送MayPass消息来通知发送者可以通过。如果许可量达到零，则actor将转换为关闭状态。在这种状态下，请求不会立即得到答复，而是将发送者的引用添加到队列中。一旦通过发送ReplenishTokens消息来补充未决许可的计时器触发，我们将增加未决许可计数器，并向每个等待的发送者发送回复。如果等待发送者的数量超出可用许可的数量，我们将保持关闭状态。
```java
static class Limiter extends AbstractActor {
 public static class WantToPass {}
 public static final WantToPass WANT_TO_PASS = new WantToPass();
 public static class MayPass {}
 public static final MayPass MAY_PASS = new MayPass();
 public static class ReplenishTokens {}
 public static final ReplenishTokens REPLENISH_TOKENS = new ReplenishTokens();
 private final int maxAvailableTokens; private final Duration tokenRefreshPeriod; private final int tokenRefreshAmount;
 private final List<ActorRef> waitQueue = new ArrayList<>(); private final Cancellable replenishTimer;
 private int permitTokens;
 public static Props props( int maxAvailableTokens, Duration tokenRefreshPeriod, int tokenRefreshAmount) { return Props.create( Limiter.class, maxAvailableTokens, tokenRefreshPeriod, tokenRefreshAmount); }
 private Limiter(int maxAvailableTokens, Duration tokenRefreshPeriod, int tokenRefreshAmount) { this.maxAvailableTokens = maxAvailableTokens; this.tokenRefreshPeriod = tokenRefreshPeriod; this.tokenRefreshAmount = tokenRefreshAmount; this.permitTokens = maxAvailableTokens;
 this.replenishTimer = system .scheduler() .scheduleWithFixedDelay( this.tokenRefreshPeriod, this.tokenRefreshPeriod, getSelf(), REPLENISH_TOKENS, getContext().getSystem().dispatcher(), getSelf()); }
 @Override public Receive createReceive() { return open(); }
 private Receive open() { return receiveBuilder() .match( ReplenishTokens.class, rt -> { permitTokens = Math.min(permitTokens + tokenRefreshAmount, maxAvailableTokens); }) .match( WantToPass.class, wtp -> { permitTokens -= 1; getSender().tell(MAY_PASS, getSelf()); if (permitTokens == 0) { getContext().become(closed()); } }) .build(); }
 private Receive closed() { return receiveBuilder() .match( ReplenishTokens.class, rt -> { permitTokens = Math.min(permitTokens + tokenRefreshAmount, maxAvailableTokens); releaseWaiting(); }) .match( WantToPass.class, wtp -> { waitQueue.add(getSender()); }) .build(); }
 private void releaseWaiting() { final List<ActorRef> toBeReleased = new ArrayList<>(permitTokens); for (Iterator<ActorRef> it = waitQueue.iterator(); permitTokens > 0 && it.hasNext(); ) { toBeReleased.add(it.next()); it.remove(); permitTokens--; }
 toBeReleased.stream().forEach(ref -> ref.tell(MAY_PASS, getSelf())); if (permitTokens > 0) { getContext().become(open()); } }
 @Override public void postStop() { replenishTimer.cancel(); waitQueue.stream() .forEach( ref -> { ref.tell( new Status.Failure(new IllegalStateException("limiter stopped")), getSelf()); }); }}
```
要创建使用此全局限制器actor的Flow，我们将mapAsync函数与ask模式的组合一起使用。 我们还定义了超时，因此，如果在配置的最大等待时间段内未收到答复，则来自Ask的返回的Future将失败，这也将使相应的流失败。
```java
public <T> Flow<T, T, NotUsed> limitGlobal(ActorRef limiter, Duration maxAllowedWait) {
 final int parallelism = 4; final Flow<T, T, NotUsed> f = Flow.create();
 return f.mapAsync( parallelism, element -> { final CompletionStage<Object> limiterTriggerFuture = Patterns.ask(limiter, Limiter.WANT_TO_PASS, maxAllowedWait); return limiterTriggerFuture.thenApplyAsync(response -> element, system.dispatcher()); });}
```
>注意
用于限制的全局actor会引入全局瓶颈。您可能要为此actor分配一个专用的调度程序。
# 使用IO
将ByteString流分成有限大小的ByteString
情况：给定ByteString的流，我们想生成一个ByteString的流，该流包含相同序列的相同字节，但限制了ByteString的大小。换句话说，如果ByteString超过大小阈值，我们希望将它们切成较小的块。
这可以通过一个GraphStage来定义自定义Akka Stream运算符来实现。我们的运算符的主要逻辑在generateChunk()中，该逻辑实现以下逻辑：
如果缓冲区为空，并且上游未关闭，则拉取更多字节；如果缓冲区关闭，则完成
如果缓冲区为nonEmpty，则根据chunkSize将其拆分。这将给出我们将发出的下一个块，以及一个空的或非空的剩余缓冲区。
onPush()和onPull()都调用emitChunk()唯一的区别是，推送处理程序还通过追加到缓冲区的末尾来存储传入的块。
```java
class Chunker extends GraphStage<FlowShape<ByteString, ByteString>> {
 private final int chunkSize;
 public Inlet<ByteString> in = Inlet.<ByteString>create("Chunker.in"); public Outlet<ByteString> out = Outlet.<ByteString>create("Chunker.out"); private FlowShape<ByteString, ByteString> shape = FlowShape.of(in, out);
 public Chunker(int chunkSize) { this.chunkSize = chunkSize; }
 @Override public FlowShape<ByteString, ByteString> shape() { return shape; }
 @Override public GraphStageLogic createLogic(Attributes inheritedAttributes) { return new GraphStageLogic(shape) { private ByteString buffer = emptyByteString();
 { setHandler( out, new AbstractOutHandler() { @Override public void onPull() throws Exception { emitChunk(); } });
 setHandler( in, new AbstractInHandler() {
 @Override public void onPush() throws Exception { ByteString elem = grab(in); buffer = buffer.concat(elem); emitChunk(); }
 @Override public void onUpstreamFinish() throws Exception { if (buffer.isEmpty()) completeStage(); else { // There are elements left in buffer, so // we keep accepting downstream pulls and push from buffer until emptied. // // It might be though, that the upstream finished while it was pulled, in // which // case we will not get an onPull from the downstream, because we already // had one. // In that case we need to emit from the buffer. if (isAvailable(out)) emitChunk(); } } }); }
 private void emitChunk() { if (buffer.isEmpty()) { if (isClosed(in)) completeStage(); else pull(in); } else { Tuple2<ByteString, ByteString> split = buffer.splitAt(chunkSize); ByteString chunk = split._1(); buffer = split._2(); push(out, chunk); } } }; }}
```
## 限制通过ByteStrings流传递的字节数
情况：给定ByteString流，如果消耗了给定的最大字节数以上，我们想使该流失败。
该配方使用GraphStage来实现所需的功能。 在我们唯一覆盖的处理程序中，onPush()我们更新一个计数器，看看它是否变得大于maximumBytes。 如果发生违规，则表示失败，否则，我们将转发收到的数据块。
```java
class ByteLimiter extends GraphStage<FlowShape<ByteString, ByteString>> {
 final long maximumBytes;
 public Inlet<ByteString> in = Inlet.<ByteString>create("ByteLimiter.in"); public Outlet<ByteString> out = Outlet.<ByteString>create("ByteLimiter.out"); private FlowShape<ByteString, ByteString> shape = FlowShape.of(in, out);
 public ByteLimiter(long maximumBytes) { this.maximumBytes = maximumBytes; }
 @Override public FlowShape<ByteString, ByteString> shape() { return shape; }
 @Override public GraphStageLogic createLogic(Attributes inheritedAttributes) { return new GraphStageLogic(shape) { private int count = 0;
 { setHandler( out, new AbstractOutHandler() { @Override public void onPull() throws Exception { pull(in); } }); setHandler( in, new AbstractInHandler() { @Override public void onPush() throws Exception { ByteString chunk = grab(in); count += chunk.size(); if (count > maximumBytes) { failStage(new IllegalStateException("Too much bytes")); } else { push(out, chunk); } } }); } }; }}
Flow<ByteString, ByteString, NotUsed> limiter =
 Flow.of(ByteString.class).via(new ByteLimiter(SIZE_LIMIT));```
## 在ByteString流中压缩ByteString
情况：经过一连串的转换后，由于结构不可变，因此ByteString可能会引用多个原始ByteString实例，从而不必要地保留了内存。 作为转换链的最后一步，我们希望拥有不再引用原始ByteString的干净副本。
配方是对map的简单使用，它调用ByteString元素的compact()方法。 这确实会复制基础数组，因此，如果使用的话，这应该是长链的最后一个元素。
```java
Source<ByteString, NotUsed> compacted = rawBytes.map(ByteString::compact);
```
将保持活动消息注入ByteStrings流
情况：给定一个表示为ByteString流的通信通道，我们希望注入保持活动消息，但前提是这不会干扰正常流量。
有一个内置的操作可以直接执行此操作：
```java
Flow<ByteString, ByteString, NotUsed> keepAliveInject =
 Flow.of(ByteString.class).keepAlive(Duration.ofSeconds(1), () -> keepAliveMessage);
```