# 依赖
要使用Akka Streams，请将模块添加到您的项目中：
```xml
<properties>
 <akka.version>2.6.10</akka.version> <scala.binary.version>2.13</scala.binary.version></properties>
<dependency>
 <groupId>com.typesafe.akka</groupId> <artifactId>akka-stream_${scala.binary.version}</artifactId> <version>${akka.version}</version></dependency>
```
# 介绍
当上游和下游速率不同时，尤其是在吞吐量出现峰值时，在流中引入缓冲区可能很有用。在本章中，我们将介绍如何在Akka流中使用缓冲区。
# 异步运算符的缓冲区
在本节中，我们将讨论内部缓冲区，这些缓冲区是在使用异步运算符时作为优化引入的。
要异步运行某个运算符，必须使用方法将其显式标记。异步运行意味着运算符在将元素分发给下游使用者之后，可以立即处理下一条消息。为了演示我们的意思，让我们看下面的示例：`.async()`
```java
Source.from(Arrays.asList(1, 2, 3))
 .map( i -> { System.out.println("A: " + i); return i; }) .async() .map( i -> { System.out.println("B: " + i); return i; }) .async() .map( i -> { System.out.println("C: " + i); return i; }) .async() .runWith(Sink.ignore(), system);```
运行上面的示例，可能的输出之一如下所示：
```output
A: 1
A: 2
B: 1
A: 3
B: 2
C: 1
B: 3
C: 2
C: 3
```
请注意，顺序不是A：1，B：1，C：1，A：2，B：2，C：2，这与常规融合同步执行模型相对应，下一个元素进入流之前，元素完全通过处理的流水线。下一个元素一旦发出前一个元素，便由异步运算符处理。
尽管流水线通常会提高吞吐量，但实际上，传递元素穿过异步（并因此跨越线程）边界是很昂贵的。为了摊销此成本，Akka Streams在内部使用了窗口化的批量反压策略。之所以要窗口化，是因为与“停止并等待”协议相反，多个元素可能与请求元素同时“进行中”。这也是批处理的，因为一旦从窗口缓冲区中删除了一个元素，就不会立即请求一个新元素，而是在多个元素被耗尽之后才请求多个元素。这种批处理策略降低了通过异步边界传播背压信号的通信成本。
尽管此内部协议对用户几乎是不可见的（除了增加吞吐量的影响），但在某些情况下这些细节会暴露出来。在我们之前的所有示例中，我们始终假定通过反压信号严格协调处理链的速率，从而使所有运算符的处理速度都不会比连接链的吞吐量快。但是，Akka Streams中有一些工具可以使处理链的不同部分的速率“分离”，或通过外部定时源定义流的最大吞吐量。这些情况恰好是内部批处理缓冲策略突然变得不透明的情况。
## 内部缓冲区及其影响
正如我们已经解释的那样，出于性能原因，Akka Streams为每个异步运算符引入了一个缓冲区。这些缓冲区的目的仅仅是为了优化，实际上，如果不需要提高吞吐量，那么大小1将是最自然的选择。因此，建议将这些缓冲区的大小保持较小，并仅将其增加到适合应用程序吞吐量要求的水平。可以通过配置设置默认缓冲区大小：
```java
final Flow<Integer, Integer, NotUsed> flow1 =
 Flow.of(Integer.class) .map(elem -> elem * 2) .async() .addAttributes(Attributes.inputBuffer(1, 1)); // the buffer size of this map is 1final Flow<Integer, Integer, NotUsed> flow2 =
 flow1 .via(Flow.of(Integer.class).map(elem -> elem / 2)) .async(); // the buffer size of this map is the value from the surrounding graph it is// used in
final RunnableGraph<NotUsed> runnableGraph =
 Source.range(1, 10).via(flow1).to(Sink.foreach(elem -> System.out.println(elem)));
final RunnableGraph<NotUsed> withOverridenDefaults =
 runnableGraph.withAttributes(Attributes.inputBuffer(64, 64));```
这是一个代码示例，演示了由内部缓冲区引起的一些问题：
```java
final Duration oneSecond = Duration.ofSeconds(1);
final Source<String, Cancellable> msgSource = Source.tick(oneSecond, oneSecond, "message!");
final Source<String, Cancellable> tickSource =
 Source.tick(oneSecond.multipliedBy(3), oneSecond.multipliedBy(3), "tick");final Flow<String, Integer, NotUsed> conflate =
 Flow.of(String.class).conflateWithSeed(first -> 1, (count, elem) -> count + 1);
RunnableGraph.fromGraph(
 GraphDSL.create( b -> { // this is the asynchronous stage in this graph final FanInShape2<String, Integer, Integer> zipper = b.add(ZipWith.create((String tick, Integer count) -> count).async()); b.from(b.add(msgSource)).via(b.add(conflate)).toInlet(zipper.in1()); b.from(b.add(tickSource)).toInlet(zipper.in0()); b.from(zipper.out()).to(b.add(Sink.foreach(elem -> System.out.println(elem)))); return ClosedShape.getInstance(); })) .run(system);```
运行上面的示例，将期望每3秒打印一次数字3（配置了conflateWithSeed步骤，以便在下游“ ZipWith”消耗它们之前计算接收到的元素数）。 不过，打印的内容有所不同，我们将看到数字1。其原因是内部缓冲区，默认情况下，内部缓冲区大16个元素，并在“ ZipWith”开始使用它们之前预取元素。 可以通过将`ZipWith`的缓冲区大小更改为1来解决此问题。尽管这是由`ZipWith`元素的初始预取引起的，我们仍然会看到前导1。
>注意
通常，当时间或速率驱动的运算符表现出奇怪的行为时，首先要尝试的解决方案之一应该是将受影响元素的输入缓冲区减小为1。
# Akka流中的缓冲区
在本节中，我们将讨论用户定义的显式缓冲区，这些缓冲区是应用程序流处理管道的域逻辑的一部分。
下面的示例将确保从外部（虚拟）系统出队1000个作业（但不多），并本地存储在内存中-减轻外部系统的负担：
```java
// Getting a stream of jobs from an imaginary external system as a Source
final Source<Job, NotUsed> jobs = inboundJobsConnector;
jobs.buffer(1000, OverflowStrategy.backpressure());
```
下一个示例还将在本地排队1000个作业，但是如果假想的外部系统中有更多的作业在等待，则通过从缓冲区的尾部删除一个元素来为新元素腾出空间。 从尾巴掉下来是一种非常普遍的策略，但是必须注意，这将放弃最年轻的等待工作。 如果从某种意义上说我们希望对已经等待很长时间的工作感到“公平”，那么此选项将很有用。
```java
jobs.buffer(1000, OverflowStrategy.dropTail());
```
除了可以从缓冲区的尾部删除最年轻的元素外，还可以删除新元素，而无需将其排队到缓冲区中。
```java
jobs.buffer(1000, OverflowStrategy.dropNew());
```
这是另一个具有1000个作业队列的示例，但是它通过从缓冲区的开头删除一个元素来为新元素腾出空间。 这是最古老的等待工作。 如果希望在一定时期内不处理作业，将重新发送作业，这是首选策略。 最旧的元素将很快重新传输（实际上，重新传输的副本可能已经在队列中！），因此首先删除它是有意义的。
```java
jobs.buffer(1000, OverflowStrategy.dropHead());
```
`
与上面的删除策略相比，一旦缓冲区已满，dropBuffer会删除其已排队的所有1000个作业。当优先选择放弃作业而不是延迟作业时，这种积极的策略很有用。
```java
jobs.buffer(1000, OverflowStrategy.dropBuffer());
```
如果我们想象中的外部作业提供者是使用我们的API的客户端，则我们可能希望强制该客户端不能有超过1000个排队的作业，否则我们会认为它淹没并终止了连接。这可以通过错误策略来实现，一旦缓冲区已满，错误策略将使流失败。
```java
jobs.buffer(1000, OverflowStrategy.fail());
```
# 速率转换
## 了解合并
当无法通过背压或其他信号通知快速的生产者放慢速度时，conflate将来自生产者的元素组合起来直到用户发出需求信号可能是有用的。
下面是一个示例片段，总结了快速元素流到标准偏差，平均值和计算统计数据时到达的元素数。
```java
final Flow<Double, Tuple3<Double, Double, Integer>, NotUsed> statsFlow =
 Flow.of(Double.class) .conflateWithSeed( elem -> Collections.singletonList(elem), (acc, elem) -> { return Stream.concat(acc.stream(), Collections.singletonList(elem).stream()) .collect(Collectors.toList()); }) .map( s -> { final Double mean = s.stream().mapToDouble(d -> d).sum() / s.size(); final DoubleStream se = s.stream().mapToDouble(x -> Math.pow(x - mean, 2)); final Double stdDev = Math.sqrt(se.sum() / s.size()); return new Tuple3<>(stdDev, mean, s.size()); });```
此示例说明了这种流速是分离的。 流开始时的元素速率可能远高于流结束时的元素速率。
合并的另一种可能用法是，当生产者开始变得太快时，不考虑所有元素进行汇总。 下面的示例演示了在消费者无法跟上生产者的情况下如何使用合并来随机删除元素。
```java
final Double p = 0.01;
final Flow<Double, Double, NotUsed> sampleFlow =
 Flow.of(Double.class) .conflateWithSeed( elem -> Collections.singletonList(elem), (acc, elem) -> { if (r.nextDouble() < p) { return Stream.concat(acc.stream(), Collections.singletonList(elem).stream()) .collect(Collectors.toList()); } return acc; }) .mapConcat(d -> d);```
另请参阅conflate和conflateWithSeed
了解更多信息和示例。
## 了解推断和扩展
现在，我们将讨论两个运算符，即推断和扩展，以帮助应对无法满足消费者需求的缓慢生产商。 它们允许将其他值作为元素发送给使用者。
作为一个简单的推断用例，这里的流程会在消费者发出需求信号且生产者还不能提供新元素时，向消费者重复最后发出的元素。
```java
final Flow<Double, Double, NotUsed> lastFlow =
 Flow.of(Double.class).extrapolate(in -> Stream.iterate(in, i -> i).iterator());```
对于从上游发出任何元素之前可能会有下游需求的情况，可以使用initial参数extrapolate“seed”流。
```java
Double initial = 2.0;
final Flow<Double, Double, NotUsed> lastFlow =
 Flow.of(Double.class).extrapolate(in -> Stream.iterate(in, i -> i).iterator(), initial);```
外推和扩展还允许根据从下游发出的需求生成元信息。 利用这一点，这里有一个流程可以跟踪并报告快速消费方和缓慢生产方之间的偏差。
```java
final Flow<Double, Pair<Double, Integer>, NotUsed> driftFlow =
 Flow.of(Double.class) .map(d -> new Pair<>(d, 0)) .extrapolate( d -> Stream.iterate(1, i -> i + 1).map(i -> new Pair<>(d.first(), i)).iterator());```
这是带有的更简洁的表示expand。
```java
final Flow<Double, Pair<Double, Integer>, NotUsed> driftFlow =
 Flow.of(Double.class) .expand(d -> Stream.iterate(0, i -> i + 1).map(i -> new Pair<>(d, i)).iterator());```
差异是由于对Iterator-generating参数的处理不同。
虽然推断仅在下游需求未满足时才使用Iterator，但expand始终会创建Iterator并向其下游发出元素。
这使得扩展能够转换甚至过滤掉（通过提供一个空的Iterator）“原始”元素。
无论如何，由于我们在两个示例中都提供了一个非空的Iterator，这意味着如果生产者足够快，则此流的输出将报告零偏移，否则将报告较大的偏移。
另请参阅外推和扩展以获取更多信息和示例。